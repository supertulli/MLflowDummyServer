{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 0.02954,
     "end_time": "2020-01-23T13:21:38.975002",
     "exception": false,
     "start_time": "2020-01-23T13:21:38.945462",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#initialize parametrized variables\n",
    "\n",
    "experimentName = ''\n",
    "runID = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.034312,
     "end_time": "2020-01-23T13:21:39.031464",
     "exception": false,
     "start_time": "2020-01-23T13:21:38.997152",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "runID = \"125e20225426432a9b6a4926b91aa0a1\"\n",
    "experimentName = \"dummyabc\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.030502,
     "end_time": "2020-01-23T13:21:39.077199",
     "exception": false,
     "start_time": "2020-01-23T13:21:39.046697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'python3': '/home/pedro/anaconda3/envs/mlflow-7ce0d1002c6479899f7ec502c9b84f5ce61312e3/share/jupyter/kernels/python3'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jupyter_client\n",
    "jupyter_client.kernelspec.find_kernel_specs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 1.077034,
     "end_time": "2020-01-23T13:21:40.160694",
     "exception": false,
     "start_time": "2020-01-23T13:21:39.083660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import mlflow, mlflow.sklearn, mlflow.pyfunc\n",
    "from mlflow.pyfunc import PythonModel\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.041836,
     "end_time": "2020-01-23T13:21:40.208428",
     "exception": false,
     "start_time": "2020-01-23T13:21:40.166592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sets the MLflow experiment and active run\n",
    "mlflow.set_experiment(experiment_name=experimentName)\n",
    "mlflow.start_run(runID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.045248,
     "end_time": "2020-01-23T13:21:40.260485",
     "exception": false,
     "start_time": "2020-01-23T13:21:40.215237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>Wer ist Vorsitzender Mercedes-Benz Vans?</td>\n",
       "      <td>DE_brand_daimlerboard_wilfried_porth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681</th>\n",
       "      <td>Kann man sofort an Ladestationen bezahlen?</td>\n",
       "      <td>DE_charging_plugsurfing_pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Gibt es Leichtmetallräder?</td>\n",
       "      <td>DE_accessories_rims_tires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>tailormade Konfigurationsmodus</td>\n",
       "      <td>DE_apps_configurator_tailormade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2530</th>\n",
       "      <td>Ich brauche eine Instruktion zum Laden.</td>\n",
       "      <td>DE_charging_instruction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>Bist du echt?</td>\n",
       "      <td>DE_areyoureal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>Erzähle mir etwas über Martin Daum</td>\n",
       "      <td>DE_brand_daimlerboard_martin_daum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>Neuwagen Garantie smart</td>\n",
       "      <td>DE_brand_guarantee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>Wie ist denn die Sitzhöhe vom smart?</td>\n",
       "      <td>DE_car_characteristics_seat_height</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3017</th>\n",
       "      <td>Welche Wallbox ist für den Fortwo EQ empfehlen...</td>\n",
       "      <td>DE_charging_possibilities_Wallbox_differences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>Lädt ein smart lange?</td>\n",
       "      <td>DE_charging_duration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>Wie viele Mitarbeiter beschäftigt Daimler US?</td>\n",
       "      <td>DE_brand_companyfacts_employees_NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>Ich möchte Ihr Foto sehen.</td>\n",
       "      <td>DE_chitchat_botappearance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>Wie ist die Bedeutung des Namens smart?</td>\n",
       "      <td>DE_brand_smart_naming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3293</th>\n",
       "      <td>Liest du Krimis?</td>\n",
       "      <td>DE_chitchat_bot_book</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Input  \\\n",
       "1612           Wer ist Vorsitzender Mercedes-Benz Vans?   \n",
       "2681         Kann man sofort an Ladestationen bezahlen?   \n",
       "75                           Gibt es Leichtmetallräder?   \n",
       "197                      tailormade Konfigurationsmodus   \n",
       "2530            Ich brauche eine Instruktion zum Laden.   \n",
       "910                                       Bist du echt?   \n",
       "1510                 Erzähle mir etwas über Martin Daum   \n",
       "1744                            Neuwagen Garantie smart   \n",
       "2203               Wie ist denn die Sitzhöhe vom smart?   \n",
       "3017  Welche Wallbox ist für den Fortwo EQ empfehlen...   \n",
       "2411                              Lädt ein smart lange?   \n",
       "1298      Wie viele Mitarbeiter beschäftigt Daimler US?   \n",
       "3248                         Ich möchte Ihr Foto sehen.   \n",
       "2002            Wie ist die Bedeutung des Namens smart?   \n",
       "3293                                   Liest du Krimis?   \n",
       "\n",
       "                                             Intent  \n",
       "1612           DE_brand_daimlerboard_wilfried_porth  \n",
       "2681                    DE_charging_plugsurfing_pay  \n",
       "75                        DE_accessories_rims_tires  \n",
       "197                 DE_apps_configurator_tailormade  \n",
       "2530                        DE_charging_instruction  \n",
       "910                                   DE_areyoureal  \n",
       "1510              DE_brand_daimlerboard_martin_daum  \n",
       "1744                             DE_brand_guarantee  \n",
       "2203             DE_car_characteristics_seat_height  \n",
       "3017  DE_charging_possibilities_Wallbox_differences  \n",
       "2411                           DE_charging_duration  \n",
       "1298             DE_brand_companyfacts_employees_NA  \n",
       "3248                      DE_chitchat_botappearance  \n",
       "2002                          DE_brand_smart_naming  \n",
       "3293                           DE_chitchat_bot_book  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data loading from storage to be handled by project_name\n",
    "data = pd.read_csv('/home/pedro/Documentos/work/Jupyter_Python/SuperTopicModeling/BERT-service/dataset/smart-intents.csv', header=None, names=['Input','Intent'])\n",
    "data = data.sample(15)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.038781,
     "end_time": "2020-01-23T13:21:40.308604",
     "exception": false,
     "start_time": "2020-01-23T13:21:40.269823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class STMPredProba(PythonModel):\n",
    "    \n",
    "    def __init__(self, n=0):\n",
    "        self._n = n\n",
    "        self._model = None\n",
    "        \n",
    "        \n",
    "    def fit(self, df):\n",
    "        from vectorizer import vectorize\n",
    "        \n",
    "        df['sentence_vector'] = vectorize(df['Input'])\n",
    "        X = pd.DataFrame(list(df['sentence_vector']), index=df.index)\n",
    "        y= df['Intent']\n",
    "        \n",
    "        #defining pipe model\n",
    "        pipeline = Pipeline([('scaler',MinMaxScaler()),\n",
    "                             ('model', LogisticRegression(C=1,\n",
    "                                                          solver='saga',\n",
    "                                                          multi_class='multinomial',\n",
    "                                                          max_iter=10000))]) \n",
    "        #constructing accuracy\n",
    "        try: #initially can not be done when classes are unitary..\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                                y,\n",
    "                                                                test_size=0.2,\n",
    "                                                                stratify = label_series) # to be contructed from previous predictions and respective new labels to avoid retraining\n",
    "            pipeline.fit(X = X_train, y = y_train) #constructing the model to accuracy -> to be cut out: see above\n",
    "            acc = pipeline.score(X = X_test,y = y_test)\n",
    "            print(acc)\n",
    "            mlflow.log_metric('accuracy',acc)\n",
    "        except:\n",
    "            pass\n",
    "        # training the model to be served\n",
    "        pipeline.fit(X, y)\n",
    "        #store the MLflow model \n",
    "#        mlflow.sklearn.log_model(pipeline,'SupTopModel')\n",
    "        self._model = pipeline\n",
    "        return None\n",
    "\n",
    "    def predict(self, df, n=0):#, pipe_model, n=0):\n",
    "        from vectorizer import vectorize\n",
    "        \n",
    "        df['sentence_vector'] = vectorize(df['Input'])\n",
    "        vector_df = pd.DataFrame(list(df['sentence_vector']), index=df.index)        \n",
    "        prob_df = pd.DataFrame(self._model.predict_proba(vector_df), index=vector_df.index, columns=self._model.classes_)\n",
    "        \n",
    "        if n ==0:\n",
    "            return prob_df\n",
    "        else:\n",
    "            top_n = np.argpartition(prob_df.transpose(), -self._n, axis=0)[-self._n:].apply(lambda x:\n",
    "                                                                                  prob_df.transpose().index.values[\n",
    "                                                                                      x]).transpose()\n",
    "            top_n.columns = [\"{}\".format(i+1) for i in range(self._n)]\n",
    "            prob_matrix = pd.DataFrame()\n",
    "            for col in top_n.columns:\n",
    "                prob_matrix[col] = prob_df.apply(lambda row: row[top_n[col][row.name]], axis=1)\n",
    "            top_prob = pd.merge(top_n, prob_matrix, right_index=True, left_index=True)\n",
    "            tuple_class_prob = pd.DataFrame()\n",
    "            for i in range(1, self._n+1): #constructs the tuple table\n",
    "                runner_x = '_'.join([str(i), 'x'])\n",
    "                runner_y = '_'.join([str(i), 'y'])\n",
    "                tuple_class_prob[i] = pd.DataFrame([top_prob[runner_x], top_prob[runner_y]]).transpose().apply(tuple,\n",
    "                                                                                                           axis=1)\n",
    "            tuple_class_prob.columns = [f\"top{i+1}\"+str(i) for i in range(1, self._n+1)]\n",
    "            for i in range(len(tuple_class_prob)): #sorts the tuple table\n",
    "                list_to_sort=tuple_class_prob.iloc[i].tolist()\n",
    "                list_to_sort.sort(key=lambda x: -x[1])\n",
    "                tuple_class_prob.iloc[i]=list_to_sort\n",
    "            return tuple_class_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.017601,
     "end_time": "2020-01-23T13:21:40.335971",
     "exception": false,
     "start_time": "2020-01-23T13:21:40.318370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MLflow_model = STMPredProba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 2.328472,
     "end_time": "2020-01-23T13:21:42.673570",
     "exception": false,
     "start_time": "2020-01-23T13:21:40.345098",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "MLflow_model.fit(data)\n",
    "\n",
    "MLflow_model.predict(data)\n",
    "mlflow.sklearn.log_model(MLflow_model,'SupTopModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.010762,
     "end_time": "2020-01-23T13:21:42.694635",
     "exception": false,
     "start_time": "2020-01-23T13:21:42.683873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "papermill": {
   "duration": 5.016156,
   "end_time": "2020-01-23T13:21:43.117783",
   "environment_variables": {},
   "exception": null,
   "input_path": "./dummytrain.ipynb",
   "output_path": "./dummytrain_out.ipynb",
   "parameters": {
    "experimentName": "dummyabc",
    "runID": "125e20225426432a9b6a4926b91aa0a1"
   },
   "start_time": "2020-01-23T13:21:38.101627",
   "version": "1.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}