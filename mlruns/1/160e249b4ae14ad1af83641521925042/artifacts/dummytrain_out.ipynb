{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 0.039205,
     "end_time": "2020-01-17T10:36:09.847507",
     "exception": false,
     "start_time": "2020-01-17T10:36:09.808302",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#initialize parametrized variables\n",
    "\n",
    "experimentName = ''\n",
    "runID = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.030442,
     "end_time": "2020-01-17T10:36:09.900814",
     "exception": false,
     "start_time": "2020-01-17T10:36:09.870372",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "runID = \"160e249b4ae14ad1af83641521925042\"\n",
    "experimentName = \"dummyabc\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.038152,
     "end_time": "2020-01-17T10:36:09.951049",
     "exception": false,
     "start_time": "2020-01-17T10:36:09.912897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'python3': '/home/pedro/anaconda3/envs/mlflow-7ce0d1002c6479899f7ec502c9b84f5ce61312e3/share/jupyter/kernels/python3'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jupyter_client\n",
    "jupyter_client.kernelspec.find_kernel_specs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 1.018666,
     "end_time": "2020-01-17T10:36:10.975925",
     "exception": false,
     "start_time": "2020-01-17T10:36:09.957259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import mlflow, mlflow.sklearn, mlflow.pyfunc\n",
    "from mlflow.pyfunc import PythonModel\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.038279,
     "end_time": "2020-01-17T10:36:11.020658",
     "exception": false,
     "start_time": "2020-01-17T10:36:10.982379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sets the MLflow experiment and active run\n",
    "mlflow.set_experiment(experiment_name=experimentName)\n",
    "mlflow.start_run(runID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.043927,
     "end_time": "2020-01-17T10:36:11.071083",
     "exception": false,
     "start_time": "2020-01-17T10:36:11.027156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3657</th>\n",
       "      <td>Magst du singen?</td>\n",
       "      <td>DE_chitchat_bot_sing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3256</th>\n",
       "      <td>Darf ich ein Foto von Ihnen sehen?</td>\n",
       "      <td>DE_chitchat_botappearance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Ist Android Auto mit dem smart kompatibel?</td>\n",
       "      <td>DE_android_car_general_info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>Wieviele Mitarbeiter hat smart in Asien</td>\n",
       "      <td>DE_brand_companyfacts_employees_malaysia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>Hast du eine Frage?</td>\n",
       "      <td>DE_chitchat_askquestion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>Wo kann ich die smart control app downloaden?</td>\n",
       "      <td>DE_apps_eqcontrol_register</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>Kraftfahrzeugsteuer Auskunft</td>\n",
       "      <td>DE_automobile_taxes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3520</th>\n",
       "      <td>Bist du sehr freundlich?</td>\n",
       "      <td>DE_chitchat_botidentity_personality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>Was kann man sich unter Plugsurfing vorstellen?</td>\n",
       "      <td>DE_charging_plugsurfing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3206</th>\n",
       "      <td>Bist du hübsch</td>\n",
       "      <td>DE_chitchat_botappearance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>Welche Fahrer können die smart eq control app ...</td>\n",
       "      <td>DE_apps_eqcontrol_users</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Kann ich die Restladezeit meines smart online ...</td>\n",
       "      <td>DE_apps_eqcontrol_carstatus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Kann ich die Reichweite meines smart online ch...</td>\n",
       "      <td>DE_apps_eqcontrol_carstatus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>Vorteil smart</td>\n",
       "      <td>DE_brand_advantages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>Stehen mehrere Lademöglichkeiten zur Auswahl?</td>\n",
       "      <td>DE_charging_possibilities</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Input  \\\n",
       "3657                                   Magst du singen?   \n",
       "3256                 Darf ich ein Foto von Ihnen sehen?   \n",
       "109          Ist Android Auto mit dem smart kompatibel?   \n",
       "1279            Wieviele Mitarbeiter hat smart in Asien   \n",
       "3145                                Hast du eine Frage?   \n",
       "490       Wo kann ich die smart control app downloaden?   \n",
       "927                        Kraftfahrzeugsteuer Auskunft   \n",
       "3520                           Bist du sehr freundlich?   \n",
       "2650    Was kann man sich unter Plugsurfing vorstellen?   \n",
       "3206                                     Bist du hübsch   \n",
       "536   Welche Fahrer können die smart eq control app ...   \n",
       "363   Kann ich die Restladezeit meines smart online ...   \n",
       "352   Kann ich die Reichweite meines smart online ch...   \n",
       "1147                                      Vorteil smart   \n",
       "2692      Stehen mehrere Lademöglichkeiten zur Auswahl?   \n",
       "\n",
       "                                        Intent  \n",
       "3657                      DE_chitchat_bot_sing  \n",
       "3256                 DE_chitchat_botappearance  \n",
       "109                DE_android_car_general_info  \n",
       "1279  DE_brand_companyfacts_employees_malaysia  \n",
       "3145                   DE_chitchat_askquestion  \n",
       "490                 DE_apps_eqcontrol_register  \n",
       "927                        DE_automobile_taxes  \n",
       "3520       DE_chitchat_botidentity_personality  \n",
       "2650                   DE_charging_plugsurfing  \n",
       "3206                 DE_chitchat_botappearance  \n",
       "536                    DE_apps_eqcontrol_users  \n",
       "363                DE_apps_eqcontrol_carstatus  \n",
       "352                DE_apps_eqcontrol_carstatus  \n",
       "1147                       DE_brand_advantages  \n",
       "2692                 DE_charging_possibilities  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data loading from storage to be handled by project_name\n",
    "data = pd.read_csv('/home/pedro/Documentos/work/Jupyter_Python/SuperTopicModeling/BERT-service/dataset/smart-intents.csv', header=None, names=['Input','Intent'])\n",
    "data = data.sample(15)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.029675,
     "end_time": "2020-01-17T10:36:11.113710",
     "exception": false,
     "start_time": "2020-01-17T10:36:11.084035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class STMPredProba(PythonModel):\n",
    "    \n",
    "    def __init__(self, n=0):\n",
    "        self._n = n\n",
    "        self._model = None\n",
    "        \n",
    "        \n",
    "    def fit(self, df):\n",
    "        from vectorizer import vectorize\n",
    "        \n",
    "        df['sentence_vector'] = vectorize(df['Input'])\n",
    "        X = pd.DataFrame(list(df['sentence_vector']), index=df.index)\n",
    "        y= df['Intent']\n",
    "        \n",
    "        #defining pipe model\n",
    "        pipeline = Pipeline([('scaler',MinMaxScaler()),\n",
    "                             ('model', LogisticRegression(C=1,\n",
    "                                                          solver='saga',\n",
    "                                                          multi_class='multinomial',\n",
    "                                                          max_iter=10000))]) \n",
    "        #constructing accuracy\n",
    "        try: #initially can not be done when classes are unitary..\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                                y,\n",
    "                                                                test_size=0.2,\n",
    "                                                                stratify = label_series) # to be contructed from previous predictions and respective new labels to avoid retraining\n",
    "            pipeline.fit(X = X_train, y = y_train) #constructing the model to accuracy -> to be cut out: see above\n",
    "            acc = pipeline.score(X = X_test,y = y_test)\n",
    "            print(acc)\n",
    "            mlflow.log_metric('accuracy',acc)\n",
    "        except:\n",
    "            pass\n",
    "        # training the model to be served\n",
    "        pipeline.fit(X, y)\n",
    "        #store the MLflow model \n",
    "#        mlflow.sklearn.log_model(pipeline,'SupTopModel')\n",
    "        self._model = pipeline\n",
    "        return None\n",
    "\n",
    "    def predict(self, df, n=0):#, pipe_model, n=0):\n",
    "        from vectorizer import vectorize\n",
    "        \n",
    "        df['sentence_vector'] = vectorize(df['Input'])\n",
    "        vector_df = pd.DataFrame(list(df['sentence_vector']), index=df.index)        \n",
    "        prob_df = pd.DataFrame(self._model.predict_proba(vector_df), index=vector_df.index, columns=self._model.classes_)\n",
    "        \n",
    "        if n ==0:\n",
    "            return prob_df\n",
    "        else:\n",
    "            top_n = np.argpartition(prob_df.transpose(), -self._n, axis=0)[-self._n:].apply(lambda x:\n",
    "                                                                                  prob_df.transpose().index.values[\n",
    "                                                                                      x]).transpose()\n",
    "            top_n.columns = [\"{}\".format(i+1) for i in range(self._n)]\n",
    "            prob_matrix = pd.DataFrame()\n",
    "            for col in top_n.columns:\n",
    "                prob_matrix[col] = prob_df.apply(lambda row: row[top_n[col][row.name]], axis=1)\n",
    "            top_prob = pd.merge(top_n, prob_matrix, right_index=True, left_index=True)\n",
    "            tuple_class_prob = pd.DataFrame()\n",
    "            for i in range(1, self._n+1): #constructs the tuple table\n",
    "                runner_x = '_'.join([str(i), 'x'])\n",
    "                runner_y = '_'.join([str(i), 'y'])\n",
    "                tuple_class_prob[i] = pd.DataFrame([top_prob[runner_x], top_prob[runner_y]]).transpose().apply(tuple,\n",
    "                                                                                                           axis=1)\n",
    "            tuple_class_prob.columns = [f\"top{i+1}\"+str(i) for i in range(1, self._n+1)]\n",
    "            for i in range(len(tuple_class_prob)): #sorts the tuple table\n",
    "                list_to_sort=tuple_class_prob.iloc[i].tolist()\n",
    "                list_to_sort.sort(key=lambda x: -x[1])\n",
    "                tuple_class_prob.iloc[i]=list_to_sort\n",
    "            return tuple_class_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.018448,
     "end_time": "2020-01-17T10:36:11.139108",
     "exception": false,
     "start_time": "2020-01-17T10:36:11.120660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MLflow_model = STMPredProba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 2.205879,
     "end_time": "2020-01-17T10:36:13.352610",
     "exception": false,
     "start_time": "2020-01-17T10:36:11.146731",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "MLflow_model.fit(data)\n",
    "\n",
    "MLflow_model.predict(data)\n",
    "mlflow.sklearn.log_model(MLflow_model,'SupTopModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.00818,
     "end_time": "2020-01-17T10:36:13.370399",
     "exception": false,
     "start_time": "2020-01-17T10:36:13.362219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "papermill": {
   "duration": 4.784316,
   "end_time": "2020-01-17T10:36:13.785248",
   "environment_variables": {},
   "exception": null,
   "input_path": "./dummytrain.ipynb",
   "output_path": "./dummytrain_out.ipynb",
   "parameters": {
    "experimentName": "dummyabc",
    "runID": "160e249b4ae14ad1af83641521925042"
   },
   "start_time": "2020-01-17T10:36:09.000932",
   "version": "1.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}