{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 0.039599,
     "end_time": "2020-01-16T15:05:34.185635",
     "exception": false,
     "start_time": "2020-01-16T15:05:34.146036",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#initialize parametrized variables\n",
    "\n",
    "experimentName = ''\n",
    "runID = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.01544,
     "end_time": "2020-01-16T15:05:34.218165",
     "exception": false,
     "start_time": "2020-01-16T15:05:34.202725",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "runID = \"f3031cc2b5ef4d2792e350972e9b8b51\"\n",
    "experimentName = \"dummyabc\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.018172,
     "end_time": "2020-01-16T15:05:34.240838",
     "exception": false,
     "start_time": "2020-01-16T15:05:34.222666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'python3': '/home/pedro/anaconda3/envs/mlflow-4b4b36ea87f6e682b2d3f4c654d8d652083d52cd/share/jupyter/kernels/python3'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jupyter_client\n",
    "jupyter_client.kernelspec.find_kernel_specs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.697947,
     "end_time": "2020-01-16T15:05:34.942992",
     "exception": false,
     "start_time": "2020-01-16T15:05:34.245045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import mlflow, mlflow.sklearn\n",
    "from mlflow.pyfunc import PythonModel\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.026939,
     "end_time": "2020-01-16T15:05:34.974445",
     "exception": false,
     "start_time": "2020-01-16T15:05:34.947506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sets the MLflow experiment and active run\n",
    "mlflow.set_experiment(experiment_name=experimentName)\n",
    "mlflow.start_run(runID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.019112,
     "end_time": "2020-01-16T15:05:34.998800",
     "exception": false,
     "start_time": "2020-01-16T15:05:34.979688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data loading from storage to be handled by project_name\n",
    "data = pd.read_csv('/home/pedro/Documentos/work/Jupyter_Python/SuperTopicModeling/BERT-service/dataset/smart-intents.csv', header=None, names=['Input','Intent'])\n",
    "data = data.sample(1500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.020477,
     "end_time": "2020-01-16T15:05:35.023656",
     "exception": false,
     "start_time": "2020-01-16T15:05:35.003179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class STMPredProba(PythonModel):\n",
    "    \n",
    "    def __init__(self, n):\n",
    "        self._n = n\n",
    "        self._model = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        #defining pipe model\n",
    "        pipeline = Pipeline([('scaler',MinMaxScaler()),\n",
    "                             ('model', LogisticRegression(C=1,\n",
    "                                                          solver='saga',\n",
    "                                                          multi_class='multinomial',\n",
    "                                                          max_iter=10000))]) \n",
    "        #constructing accuracy\n",
    "        try: #initially can not be done when classes are unitary..\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                                y,\n",
    "                                                                test_size=0.2,\n",
    "                                                                stratify = label_series) # to be contructed from previous predictions and respective new labels to avoid retraining\n",
    "            pipeline.fit(X = X_train, y = y_train) #constructing the model to accuracy -> to be cut out: see above\n",
    "            acc = pipeline.score(X = X_test,y = y_test)\n",
    "            print(acc)\n",
    "            mlflow.log_metric('accuracy',acc)\n",
    "        except:\n",
    "            pass\n",
    "        # training the model to be served\n",
    "        pipeline.fit(X, y)\n",
    "        #store the MLflow model \n",
    "        mlflow.sklearn.log_model(pipeline,'SupTopModel')\n",
    "        self._model = pipeline\n",
    "        return None\n",
    "\n",
    "    def predict(self, X, n=0):#, pipe_model, n=0):\n",
    "        \n",
    "        from vectorizer import vectorize\n",
    "        \n",
    "        X['sentence_vector'] = vectorize(X['Input'])\n",
    "        vector_df = pd.DataFrame(list(X['sentence_vector']), index=data.index)        \n",
    "        prob_df = pd.DataFrame(self._model.predict_proba(vector_df), index=vector_df.index, columns=self._model.classes_)\n",
    "        \n",
    "        if n ==0:\n",
    "            return prob_df\n",
    "        else:\n",
    "            top_n = np.argpartition(prob_df.transpose(), -self._n, axis=0)[-self._n:].apply(lambda x:\n",
    "                                                                                  prob_df.transpose().index.values[\n",
    "                                                                                      x]).transpose()\n",
    "            top_n.columns = [\"{}\".format(i+1) for i in range(self._n)]\n",
    "            prob_matrix = pd.DataFrame()\n",
    "            for col in top_n.columns:\n",
    "                prob_matrix[col] = prob_df.apply(lambda row: row[top_n[col][row.name]], axis=1)\n",
    "            top_prob = pd.merge(top_n, prob_matrix, right_index=True, left_index=True)\n",
    "            tuple_class_prob = pd.DataFrame()\n",
    "            for i in range(1, self._n+1): #constructs the tuple table\n",
    "                runner_x = '_'.join([str(i), 'x'])\n",
    "                runner_y = '_'.join([str(i), 'y'])\n",
    "                tuple_class_prob[i] = pd.DataFrame([top_prob[runner_x], top_prob[runner_y]]).transpose().apply(tuple,\n",
    "                                                                                                           axis=1)\n",
    "            tuple_class_prob.columns = [f\"top{i+1}\"+str(i) for i in range(1, self._n+1)]\n",
    "            for i in range(len(tuple_class_prob)): #sorts the tuple table\n",
    "                list_to_sort=tuple_class_prob.iloc[i].tolist()\n",
    "                list_to_sort.sort(key=lambda x: -x[1])\n",
    "                tuple_class_prob.iloc[i]=list_to_sort\n",
    "            return tuple_class_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.009494,
     "end_time": "2020-01-16T15:05:35.037628",
     "exception": false,
     "start_time": "2020-01-16T15:05:35.028134",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#mlflow.end_run()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "papermill": {
   "duration": 1.938062,
   "end_time": "2020-01-16T15:05:35.449347",
   "environment_variables": {},
   "exception": null,
   "input_path": "./dummytrain.ipynb",
   "output_path": "./dummytrain_out.ipynb",
   "parameters": {
    "experimentName": "dummyabc",
    "runID": "f3031cc2b5ef4d2792e350972e9b8b51"
   },
   "start_time": "2020-01-16T15:05:33.511285",
   "version": "1.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}