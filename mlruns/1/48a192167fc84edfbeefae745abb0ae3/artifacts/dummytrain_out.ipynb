{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 0.034788,
     "end_time": "2020-01-23T12:03:35.669106",
     "exception": false,
     "start_time": "2020-01-23T12:03:35.634318",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#initialize parametrized variables\n",
    "\n",
    "experimentName = ''\n",
    "runID = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.015392,
     "end_time": "2020-01-23T12:03:35.696775",
     "exception": false,
     "start_time": "2020-01-23T12:03:35.681383",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "runID = \"48a192167fc84edfbeefae745abb0ae3\"\n",
    "experimentName = \"dummyabc\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.020235,
     "end_time": "2020-01-23T12:03:35.723486",
     "exception": false,
     "start_time": "2020-01-23T12:03:35.703251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'python3': '/home/pedro/anaconda3/envs/mlflow-7ce0d1002c6479899f7ec502c9b84f5ce61312e3/share/jupyter/kernels/python3'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jupyter_client\n",
    "jupyter_client.kernelspec.find_kernel_specs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.924113,
     "end_time": "2020-01-23T12:03:36.653979",
     "exception": false,
     "start_time": "2020-01-23T12:03:35.729866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import mlflow, mlflow.sklearn, mlflow.pyfunc\n",
    "from mlflow.pyfunc import PythonModel\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.033958,
     "end_time": "2020-01-23T12:03:36.693935",
     "exception": false,
     "start_time": "2020-01-23T12:03:36.659977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sets the MLflow experiment and active run\n",
    "mlflow.set_experiment(experiment_name=experimentName)\n",
    "mlflow.start_run(runID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.036248,
     "end_time": "2020-01-23T12:03:36.736069",
     "exception": false,
     "start_time": "2020-01-23T12:03:36.699821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>Mehr Informationen über die Vorsitzende bei Me...</td>\n",
       "      <td>DE_brand_daimlerboard_britta_seeger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>Sag mir etwas über den Radstand beim smart</td>\n",
       "      <td>DE_car_characteristics_wheelbase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>Warum sind die smarts vorteilhaft?</td>\n",
       "      <td>DE_brand_advantages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>iPhone Integration</td>\n",
       "      <td>DE_apps_carplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>Wie viel kostet eine Ladung?</td>\n",
       "      <td>DE_charging_cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3433</th>\n",
       "      <td>Welchen smart w�rdest du vorziehen?</td>\n",
       "      <td>DE_chitchat_bot_favoritesmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>Ich suche eine Gebrauchsanleitung zum Laden.</td>\n",
       "      <td>DE_charging_instruction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>Gibt es einen Anbieter hinter der Bezahlung vo...</td>\n",
       "      <td>DE_charging_plugsurfing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>Kannst du beschreiben wie du aussiehst</td>\n",
       "      <td>DE_chitchat_botappearance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Wo kann ich den Konfigurator Code eingeben?</td>\n",
       "      <td>DE_apps_configurator_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>Soll ich einen 22 kw Bordlader oder einen 4,6k...</td>\n",
       "      <td>DE_charging_onboardcharger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>Lust auf quatschen?</td>\n",
       "      <td>DE_chit_chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>Ich möchte gern Genaueres zum Thema smart welt...</td>\n",
       "      <td>DE_apps_smart_world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2737</th>\n",
       "      <td>wann kann ich laden</td>\n",
       "      <td>DE_charging_possibilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>Kann man eine App downloaden?</td>\n",
       "      <td>DE_apps_unspecified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Input  \\\n",
       "1380  Mehr Informationen über die Vorsitzende bei Me...   \n",
       "2257         Sag mir etwas über den Radstand beim smart   \n",
       "1144                 Warum sind die smarts vorteilhaft?   \n",
       "120                                  iPhone Integration   \n",
       "2387                       Wie viel kostet eine Ladung?   \n",
       "3433                Welchen smart w�rdest du vorziehen?   \n",
       "2525       Ich suche eine Gebrauchsanleitung zum Laden.   \n",
       "2622  Gibt es einen Anbieter hinter der Bezahlung vo...   \n",
       "3215             Kannst du beschreiben wie du aussiehst   \n",
       "160         Wo kann ich den Konfigurator Code eingeben?   \n",
       "2585  Soll ich einen 22 kw Bordlader oder einen 4,6k...   \n",
       "3040                                Lust auf quatschen?   \n",
       "760   Ich möchte gern Genaueres zum Thema smart welt...   \n",
       "2737                                wann kann ich laden   \n",
       "811                       Kann man eine App downloaden?   \n",
       "\n",
       "                                   Intent  \n",
       "1380  DE_brand_daimlerboard_britta_seeger  \n",
       "2257     DE_car_characteristics_wheelbase  \n",
       "1144                  DE_brand_advantages  \n",
       "120                       DE_apps_carplay  \n",
       "2387                     DE_charging_cost  \n",
       "3433        DE_chitchat_bot_favoritesmart  \n",
       "2525              DE_charging_instruction  \n",
       "2622              DE_charging_plugsurfing  \n",
       "3215            DE_chitchat_botappearance  \n",
       "160             DE_apps_configurator_code  \n",
       "2585           DE_charging_onboardcharger  \n",
       "3040                         DE_chit_chat  \n",
       "760                   DE_apps_smart_world  \n",
       "2737            DE_charging_possibilities  \n",
       "811                   DE_apps_unspecified  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data loading from storage to be handled by project_name\n",
    "data = pd.read_csv('/home/pedro/Documentos/work/Jupyter_Python/SuperTopicModeling/BERT-service/dataset/smart-intents.csv', header=None, names=['Input','Intent'])\n",
    "data = data.sample(15)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.025174,
     "end_time": "2020-01-23T12:03:36.770881",
     "exception": false,
     "start_time": "2020-01-23T12:03:36.745707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class STMPredProba(PythonModel):\n",
    "    \n",
    "    def __init__(self, n=0):\n",
    "        self._n = n\n",
    "        self._model = None\n",
    "        \n",
    "        \n",
    "    def fit(self, df):\n",
    "        from vectorizer import vectorize\n",
    "        \n",
    "        df['sentence_vector'] = vectorize(df['Input'])\n",
    "        X = pd.DataFrame(list(df['sentence_vector']), index=df.index)\n",
    "        y= df['Intent']\n",
    "        \n",
    "        #defining pipe model\n",
    "        pipeline = Pipeline([('scaler',MinMaxScaler()),\n",
    "                             ('model', LogisticRegression(C=1,\n",
    "                                                          solver='saga',\n",
    "                                                          multi_class='multinomial',\n",
    "                                                          max_iter=10000))]) \n",
    "        #constructing accuracy\n",
    "        try: #initially can not be done when classes are unitary..\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                                y,\n",
    "                                                                test_size=0.2,\n",
    "                                                                stratify = label_series) # to be contructed from previous predictions and respective new labels to avoid retraining\n",
    "            pipeline.fit(X = X_train, y = y_train) #constructing the model to accuracy -> to be cut out: see above\n",
    "            acc = pipeline.score(X = X_test,y = y_test)\n",
    "            print(acc)\n",
    "            mlflow.log_metric('accuracy',acc)\n",
    "        except:\n",
    "            pass\n",
    "        # training the model to be served\n",
    "        pipeline.fit(X, y)\n",
    "        #store the MLflow model \n",
    "#        mlflow.sklearn.log_model(pipeline,'SupTopModel')\n",
    "        self._model = pipeline\n",
    "        return None\n",
    "\n",
    "    def predict(self, df, n=0):#, pipe_model, n=0):\n",
    "        from vectorizer import vectorize\n",
    "        \n",
    "        df['sentence_vector'] = vectorize(df['Input'])\n",
    "        vector_df = pd.DataFrame(list(df['sentence_vector']), index=df.index)        \n",
    "        prob_df = pd.DataFrame(self._model.predict_proba(vector_df), index=vector_df.index, columns=self._model.classes_)\n",
    "        \n",
    "        if n ==0:\n",
    "            return prob_df\n",
    "        else:\n",
    "            top_n = np.argpartition(prob_df.transpose(), -self._n, axis=0)[-self._n:].apply(lambda x:\n",
    "                                                                                  prob_df.transpose().index.values[\n",
    "                                                                                      x]).transpose()\n",
    "            top_n.columns = [\"{}\".format(i+1) for i in range(self._n)]\n",
    "            prob_matrix = pd.DataFrame()\n",
    "            for col in top_n.columns:\n",
    "                prob_matrix[col] = prob_df.apply(lambda row: row[top_n[col][row.name]], axis=1)\n",
    "            top_prob = pd.merge(top_n, prob_matrix, right_index=True, left_index=True)\n",
    "            tuple_class_prob = pd.DataFrame()\n",
    "            for i in range(1, self._n+1): #constructs the tuple table\n",
    "                runner_x = '_'.join([str(i), 'x'])\n",
    "                runner_y = '_'.join([str(i), 'y'])\n",
    "                tuple_class_prob[i] = pd.DataFrame([top_prob[runner_x], top_prob[runner_y]]).transpose().apply(tuple,\n",
    "                                                                                                           axis=1)\n",
    "            tuple_class_prob.columns = [f\"top{i+1}\"+str(i) for i in range(1, self._n+1)]\n",
    "            for i in range(len(tuple_class_prob)): #sorts the tuple table\n",
    "                list_to_sort=tuple_class_prob.iloc[i].tolist()\n",
    "                list_to_sort.sort(key=lambda x: -x[1])\n",
    "                tuple_class_prob.iloc[i]=list_to_sort\n",
    "            return tuple_class_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.016753,
     "end_time": "2020-01-23T12:03:36.795620",
     "exception": false,
     "start_time": "2020-01-23T12:03:36.778867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MLflow_model = STMPredProba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 2.201423,
     "end_time": "2020-01-23T12:03:39.003108",
     "exception": false,
     "start_time": "2020-01-23T12:03:36.801685",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "MLflow_model.fit(data)\n",
    "\n",
    "MLflow_model.predict(data)\n",
    "mlflow.sklearn.log_model(MLflow_model,'SupTopModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.010724,
     "end_time": "2020-01-23T12:03:39.023858",
     "exception": false,
     "start_time": "2020-01-23T12:03:39.013134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "papermill": {
   "duration": 4.568263,
   "end_time": "2020-01-23T12:03:39.438028",
   "environment_variables": {},
   "exception": null,
   "input_path": "./dummytrain.ipynb",
   "output_path": "./dummytrain_out.ipynb",
   "parameters": {
    "experimentName": "dummyabc",
    "runID": "48a192167fc84edfbeefae745abb0ae3"
   },
   "start_time": "2020-01-23T12:03:34.869765",
   "version": "1.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}