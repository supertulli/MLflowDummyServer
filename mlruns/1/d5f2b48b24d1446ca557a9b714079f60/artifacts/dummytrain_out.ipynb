{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 0.046264,
     "end_time": "2020-01-16T17:36:23.118836",
     "exception": false,
     "start_time": "2020-01-16T17:36:23.072572",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#initialize parametrized variables\n",
    "\n",
    "experimentName = ''\n",
    "runID = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.016709,
     "end_time": "2020-01-16T17:36:23.156056",
     "exception": false,
     "start_time": "2020-01-16T17:36:23.139347",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "runID = \"d5f2b48b24d1446ca557a9b714079f60\"\n",
    "experimentName = \"dummyabc\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.019229,
     "end_time": "2020-01-16T17:36:23.180502",
     "exception": false,
     "start_time": "2020-01-16T17:36:23.161273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'python3': '/home/pedro/anaconda3/envs/mlflow-7ce0d1002c6479899f7ec502c9b84f5ce61312e3/share/jupyter/kernels/python3'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jupyter_client\n",
    "jupyter_client.kernelspec.find_kernel_specs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.700127,
     "end_time": "2020-01-16T17:36:23.885640",
     "exception": false,
     "start_time": "2020-01-16T17:36:23.185513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import mlflow, mlflow.sklearn, mlflow.pyfunc\n",
    "from mlflow.pyfunc import PythonModel\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.034608,
     "end_time": "2020-01-16T17:36:23.925291",
     "exception": false,
     "start_time": "2020-01-16T17:36:23.890683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sets the MLflow experiment and active run\n",
    "mlflow.set_experiment(experiment_name=experimentName)\n",
    "mlflow.start_run(runID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.030184,
     "end_time": "2020-01-16T17:36:23.964829",
     "exception": false,
     "start_time": "2020-01-16T17:36:23.934645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2682</th>\n",
       "      <td>Wie bezahlt man nach dem Ladevorgang?</td>\n",
       "      <td>DE_charging_plugsurfing_pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>Welche Auswahlmöglichkeiten stehen zur Verfügu...</td>\n",
       "      <td>DE_charging_possibilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638</th>\n",
       "      <td>Ich will, dass du für mich singst</td>\n",
       "      <td>DE_chitchat_bot_sing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872</th>\n",
       "      <td>Kann ich auch eine normale Steckdose benutzen,...</td>\n",
       "      <td>DE_charging_possibilities_socket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>Ich suche interaktive Apps zum Thema Elektromo...</td>\n",
       "      <td>DE_apps_experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>Bist du ein boot</td>\n",
       "      <td>DE_areyoureal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>Wie viel Volt beträgt der Ladestrom wenn man d...</td>\n",
       "      <td>DE_charging_capacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Woher bekomme ich die connecting app?</td>\n",
       "      <td>DE_apps_crossconnect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>Wer erfand smart?</td>\n",
       "      <td>DE_brand_companyfacts_smart_founder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>Ich möchte den günstigen Strompreis finden?</td>\n",
       "      <td>DE_apps_eqcontrol_carstatus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>bodypanel - wie funktioniert das?</td>\n",
       "      <td>DE_bodypanels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>Ist das Laden am normalen Stromnetz möglich?</td>\n",
       "      <td>DE_charging_possibilities_socket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>Wie viele Menschen arbeiten für smart Südafrika?</td>\n",
       "      <td>DE_brand_companyfacts_employees_southafrica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>Kann ich mein Auto auch im Ausland laden?</td>\n",
       "      <td>DE_charging_possibilities_publicstations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>Ich möchte mich bei smart bewerben.</td>\n",
       "      <td>DE_brand_job_offer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Input  \\\n",
       "2682              Wie bezahlt man nach dem Ladevorgang?   \n",
       "2747  Welche Auswahlmöglichkeiten stehen zur Verfügu...   \n",
       "3638                  Ich will, dass du für mich singst   \n",
       "2872  Kann ich auch eine normale Steckdose benutzen,...   \n",
       "592   Ich suche interaktive Apps zum Thema Elektromo...   \n",
       "920                                    Bist du ein boot   \n",
       "2359  Wie viel Volt beträgt der Ladestrom wenn man d...   \n",
       "263               Woher bekomme ich die connecting app?   \n",
       "1361                                  Wer erfand smart?   \n",
       "383         Ich möchte den günstigen Strompreis finden?   \n",
       "993                   bodypanel - wie funktioniert das?   \n",
       "2864       Ist das Laden am normalen Stromnetz möglich?   \n",
       "1331   Wie viele Menschen arbeiten für smart Südafrika?   \n",
       "2781          Kann ich mein Auto auch im Ausland laden?   \n",
       "1814                Ich möchte mich bei smart bewerben.   \n",
       "\n",
       "                                           Intent  \n",
       "2682                  DE_charging_plugsurfing_pay  \n",
       "2747                    DE_charging_possibilities  \n",
       "3638                         DE_chitchat_bot_sing  \n",
       "2872             DE_charging_possibilities_socket  \n",
       "592                            DE_apps_experience  \n",
       "920                                 DE_areyoureal  \n",
       "2359                         DE_charging_capacity  \n",
       "263                          DE_apps_crossconnect  \n",
       "1361          DE_brand_companyfacts_smart_founder  \n",
       "383                   DE_apps_eqcontrol_carstatus  \n",
       "993                                 DE_bodypanels  \n",
       "2864             DE_charging_possibilities_socket  \n",
       "1331  DE_brand_companyfacts_employees_southafrica  \n",
       "2781     DE_charging_possibilities_publicstations  \n",
       "1814                           DE_brand_job_offer  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data loading from storage to be handled by project_name\n",
    "data = pd.read_csv('/home/pedro/Documentos/work/Jupyter_Python/SuperTopicModeling/BERT-service/dataset/smart-intents.csv', header=None, names=['Input','Intent'])\n",
    "data = data.sample(15)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.025318,
     "end_time": "2020-01-16T17:36:23.995919",
     "exception": false,
     "start_time": "2020-01-16T17:36:23.970601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great\n"
     ]
    }
   ],
   "source": [
    "class STMPredProba(PythonModel):\n",
    "    \n",
    "    def __init__(self, n=0):\n",
    "        self._n = n\n",
    "        self._model = None\n",
    "        \n",
    "        \n",
    "    def fit(self, df):\n",
    "        from vectorizer import vectorize\n",
    "        \n",
    "        df['sentence_vector'] = vectorize(df['Input'])\n",
    "        X = pd.DataFrame(list(df['sentence_vector']), index=df.index)\n",
    "        y= df['Intent']\n",
    "        \n",
    "        #defining pipe model\n",
    "        pipeline = Pipeline([('scaler',MinMaxScaler()),\n",
    "                             ('model', LogisticRegression(C=1,\n",
    "                                                          solver='saga',\n",
    "                                                          multi_class='multinomial',\n",
    "                                                          max_iter=10000))]) \n",
    "        #constructing accuracy\n",
    "        try: #initially can not be done when classes are unitary..\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                                y,\n",
    "                                                                test_size=0.2,\n",
    "                                                                stratify = label_series) # to be contructed from previous predictions and respective new labels to avoid retraining\n",
    "            pipeline.fit(X = X_train, y = y_train) #constructing the model to accuracy -> to be cut out: see above\n",
    "            acc = pipeline.score(X = X_test,y = y_test)\n",
    "            print(acc)\n",
    "            mlflow.log_metric('accuracy',acc)\n",
    "        except:\n",
    "            pass\n",
    "        # training the model to be served\n",
    "        pipeline.fit(X, y)\n",
    "        #store the MLflow model \n",
    "#        mlflow.sklearn.log_model(pipeline,'SupTopModel')\n",
    "        self._model = pipeline\n",
    "        return None\n",
    "\n",
    "    def predict(self, df, n=0):#, pipe_model, n=0):\n",
    "        from vectorizer import vectorize\n",
    "        \n",
    "        df['sentence_vector'] = vectorize(df['Input'])\n",
    "        vector_df = pd.DataFrame(list(df['sentence_vector']), index=df.index)        \n",
    "        prob_df = pd.DataFrame(self._model.predict_proba(vector_df), index=vector_df.index, columns=self._model.classes_)\n",
    "        \n",
    "        if n ==0:\n",
    "            return prob_df\n",
    "        else:\n",
    "            top_n = np.argpartition(prob_df.transpose(), -self._n, axis=0)[-self._n:].apply(lambda x:\n",
    "                                                                                  prob_df.transpose().index.values[\n",
    "                                                                                      x]).transpose()\n",
    "            top_n.columns = [\"{}\".format(i+1) for i in range(self._n)]\n",
    "            prob_matrix = pd.DataFrame()\n",
    "            for col in top_n.columns:\n",
    "                prob_matrix[col] = prob_df.apply(lambda row: row[top_n[col][row.name]], axis=1)\n",
    "            top_prob = pd.merge(top_n, prob_matrix, right_index=True, left_index=True)\n",
    "            tuple_class_prob = pd.DataFrame()\n",
    "            for i in range(1, self._n+1): #constructs the tuple table\n",
    "                runner_x = '_'.join([str(i), 'x'])\n",
    "                runner_y = '_'.join([str(i), 'y'])\n",
    "                tuple_class_prob[i] = pd.DataFrame([top_prob[runner_x], top_prob[runner_y]]).transpose().apply(tuple,\n",
    "                                                                                                           axis=1)\n",
    "            tuple_class_prob.columns = [f\"top{i+1}\"+str(i) for i in range(1, self._n+1)]\n",
    "            for i in range(len(tuple_class_prob)): #sorts the tuple table\n",
    "                list_to_sort=tuple_class_prob.iloc[i].tolist()\n",
    "                list_to_sort.sort(key=lambda x: -x[1])\n",
    "                tuple_class_prob.iloc[i]=list_to_sort\n",
    "            return tuple_class_prob\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        print('great')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.012537,
     "end_time": "2020-01-16T17:36:24.014736",
     "exception": false,
     "start_time": "2020-01-16T17:36:24.002199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MLflow_model = STMPredProba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 1.650737,
     "end_time": "2020-01-16T17:36:25.671701",
     "exception": false,
     "start_time": "2020-01-16T17:36:24.020964",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "MLflow_model.fit(data)\n",
    "\n",
    "MLflow_model.predict(data)\n",
    "mlflow.sklearn.log_model(MLflow_model,'SupTopModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.008765,
     "end_time": "2020-01-16T17:36:25.689807",
     "exception": false,
     "start_time": "2020-01-16T17:36:25.681042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "papermill": {
   "duration": 3.566825,
   "end_time": "2020-01-16T17:36:26.004052",
   "environment_variables": {},
   "exception": null,
   "input_path": "./dummytrain.ipynb",
   "output_path": "./dummytrain_out.ipynb",
   "parameters": {
    "experimentName": "dummyabc",
    "runID": "d5f2b48b24d1446ca557a9b714079f60"
   },
   "start_time": "2020-01-16T17:36:22.437227",
   "version": "1.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}