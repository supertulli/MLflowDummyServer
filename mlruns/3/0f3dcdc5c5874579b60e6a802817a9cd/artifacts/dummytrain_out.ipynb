{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 0.046677,
     "end_time": "2020-01-23T11:42:06.544248",
     "exception": false,
     "start_time": "2020-01-23T11:42:06.497571",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#initialize parametrized variables\n",
    "\n",
    "experimentName = ''\n",
    "runID = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.015143,
     "end_time": "2020-01-23T11:42:06.578267",
     "exception": false,
     "start_time": "2020-01-23T11:42:06.563124",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "runID = \"0f3dcdc5c5874579b60e6a802817a9cd\"\n",
    "experimentName = \"abc\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.01904,
     "end_time": "2020-01-23T11:42:06.602214",
     "exception": false,
     "start_time": "2020-01-23T11:42:06.583174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'python3': '/home/pedro/anaconda3/envs/mlflow-7ce0d1002c6479899f7ec502c9b84f5ce61312e3/share/jupyter/kernels/python3'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jupyter_client\n",
    "jupyter_client.kernelspec.find_kernel_specs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.868986,
     "end_time": "2020-01-23T11:42:07.476099",
     "exception": false,
     "start_time": "2020-01-23T11:42:06.607113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import mlflow, mlflow.sklearn, mlflow.pyfunc\n",
    "from mlflow.pyfunc import PythonModel\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.028597,
     "end_time": "2020-01-23T11:42:07.510634",
     "exception": false,
     "start_time": "2020-01-23T11:42:07.482037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sets the MLflow experiment and active run\n",
    "mlflow.set_experiment(experiment_name=experimentName)\n",
    "mlflow.start_run(runID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.034439,
     "end_time": "2020-01-23T11:42:07.551004",
     "exception": false,
     "start_time": "2020-01-23T11:42:07.516565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>Ist die Ladedauer eines EQ lang?</td>\n",
       "      <td>DE_charging_duration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>Ich hätte euch gern als Sponsor</td>\n",
       "      <td>DE_brand_sponsorship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>Ich möchte bei smart Mitarbeiter werden.</td>\n",
       "      <td>DE_brand_job_offer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>Ich möchte eine Analyse meines Fahrverhaltens.</td>\n",
       "      <td>DE_apps_eqcontrol_ecoscore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3503</th>\n",
       "      <td>Was ist dein Hauptziel?</td>\n",
       "      <td>DE_chitchat_bot_goals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>Stehen mehrere Auswahlmöglichkeiten zur Verfüg...</td>\n",
       "      <td>DE_charging_possibilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>Ich hätte gern Informationen über die PKW-Steu...</td>\n",
       "      <td>DE_automobile_taxes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2824</th>\n",
       "      <td>Kann ich meinen eq forfour in laden?</td>\n",
       "      <td>DE_charging_possibilities_publicstations_avail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>Wie kann ich zu Hause laden?</td>\n",
       "      <td>DE_charging_possibilities_socket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>Unterwegs laden - wie geht das?</td>\n",
       "      <td>DE_charging_possibilities_publicstations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>Anzahl der Mitarbeiter, die für Daimler in Asi...</td>\n",
       "      <td>DE_brand_companyfacts_employees_malaysia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>Anzahl der Mitarbeiter, die für Mercedes-Benz ...</td>\n",
       "      <td>DE_brand_companyfacts_employees_malaysia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3622</th>\n",
       "      <td>Welche Netflix-Serie empfiehlst du mir?</td>\n",
       "      <td>DE_chitchat_bot_seriesmovies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>wie viele smart händler gibt es deutschlandweit?</td>\n",
       "      <td>DE_brand_number_dealers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>PKW-Steuern</td>\n",
       "      <td>DE_automobile_taxes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Input  \\\n",
       "2408                   Ist die Ladedauer eines EQ lang?   \n",
       "2078                    Ich hätte euch gern als Sponsor   \n",
       "1789           Ich möchte bei smart Mitarbeiter werden.   \n",
       "414      Ich möchte eine Analyse meines Fahrverhaltens.   \n",
       "3503                            Was ist dein Hauptziel?   \n",
       "2694  Stehen mehrere Auswahlmöglichkeiten zur Verfüg...   \n",
       "931   Ich hätte gern Informationen über die PKW-Steu...   \n",
       "2824               Kann ich meinen eq forfour in laden?   \n",
       "2880                       Wie kann ich zu Hause laden?   \n",
       "2796                    Unterwegs laden - wie geht das?   \n",
       "1251  Anzahl der Mitarbeiter, die für Daimler in Asi...   \n",
       "1278  Anzahl der Mitarbeiter, die für Mercedes-Benz ...   \n",
       "3622            Welche Netflix-Serie empfiehlst du mir?   \n",
       "1827   wie viele smart händler gibt es deutschlandweit?   \n",
       "957                                         PKW-Steuern   \n",
       "\n",
       "                                                 Intent  \n",
       "2408                               DE_charging_duration  \n",
       "2078                               DE_brand_sponsorship  \n",
       "1789                                 DE_brand_job_offer  \n",
       "414                          DE_apps_eqcontrol_ecoscore  \n",
       "3503                              DE_chitchat_bot_goals  \n",
       "2694                          DE_charging_possibilities  \n",
       "931                                 DE_automobile_taxes  \n",
       "2824  DE_charging_possibilities_publicstations_avail...  \n",
       "2880                   DE_charging_possibilities_socket  \n",
       "2796           DE_charging_possibilities_publicstations  \n",
       "1251           DE_brand_companyfacts_employees_malaysia  \n",
       "1278           DE_brand_companyfacts_employees_malaysia  \n",
       "3622                       DE_chitchat_bot_seriesmovies  \n",
       "1827                            DE_brand_number_dealers  \n",
       "957                                 DE_automobile_taxes  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data loading from storage to be handled by project_name\n",
    "data = pd.read_csv('/home/pedro/Documentos/work/Jupyter_Python/SuperTopicModeling/BERT-service/dataset/smart-intents.csv', header=None, names=['Input','Intent'])\n",
    "data = data.sample(15)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.024369,
     "end_time": "2020-01-23T11:42:07.581293",
     "exception": false,
     "start_time": "2020-01-23T11:42:07.556924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class STMPredProba(PythonModel):\n",
    "    \n",
    "    def __init__(self, n=0):\n",
    "        self._n = n\n",
    "        self._model = None\n",
    "        \n",
    "        \n",
    "    def fit(self, df):\n",
    "        from vectorizer import vectorize\n",
    "        \n",
    "        df['sentence_vector'] = vectorize(df['Input'])\n",
    "        X = pd.DataFrame(list(df['sentence_vector']), index=df.index)\n",
    "        y= df['Intent']\n",
    "        \n",
    "        #defining pipe model\n",
    "        pipeline = Pipeline([('scaler',MinMaxScaler()),\n",
    "                             ('model', LogisticRegression(C=1,\n",
    "                                                          solver='saga',\n",
    "                                                          multi_class='multinomial',\n",
    "                                                          max_iter=10000))]) \n",
    "        #constructing accuracy\n",
    "        try: #initially can not be done when classes are unitary..\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                                y,\n",
    "                                                                test_size=0.2,\n",
    "                                                                stratify = label_series) # to be contructed from previous predictions and respective new labels to avoid retraining\n",
    "            pipeline.fit(X = X_train, y = y_train) #constructing the model to accuracy -> to be cut out: see above\n",
    "            acc = pipeline.score(X = X_test,y = y_test)\n",
    "            print(acc)\n",
    "            mlflow.log_metric('accuracy',acc)\n",
    "        except:\n",
    "            pass\n",
    "        # training the model to be served\n",
    "        pipeline.fit(X, y)\n",
    "        #store the MLflow model \n",
    "#        mlflow.sklearn.log_model(pipeline,'SupTopModel')\n",
    "        self._model = pipeline\n",
    "        return None\n",
    "\n",
    "    def predict(self, df, n=0):#, pipe_model, n=0):\n",
    "        from vectorizer import vectorize\n",
    "        \n",
    "        df['sentence_vector'] = vectorize(df['Input'])\n",
    "        vector_df = pd.DataFrame(list(df['sentence_vector']), index=df.index)        \n",
    "        prob_df = pd.DataFrame(self._model.predict_proba(vector_df), index=vector_df.index, columns=self._model.classes_)\n",
    "        \n",
    "        if n ==0:\n",
    "            return prob_df\n",
    "        else:\n",
    "            top_n = np.argpartition(prob_df.transpose(), -self._n, axis=0)[-self._n:].apply(lambda x:\n",
    "                                                                                  prob_df.transpose().index.values[\n",
    "                                                                                      x]).transpose()\n",
    "            top_n.columns = [\"{}\".format(i+1) for i in range(self._n)]\n",
    "            prob_matrix = pd.DataFrame()\n",
    "            for col in top_n.columns:\n",
    "                prob_matrix[col] = prob_df.apply(lambda row: row[top_n[col][row.name]], axis=1)\n",
    "            top_prob = pd.merge(top_n, prob_matrix, right_index=True, left_index=True)\n",
    "            tuple_class_prob = pd.DataFrame()\n",
    "            for i in range(1, self._n+1): #constructs the tuple table\n",
    "                runner_x = '_'.join([str(i), 'x'])\n",
    "                runner_y = '_'.join([str(i), 'y'])\n",
    "                tuple_class_prob[i] = pd.DataFrame([top_prob[runner_x], top_prob[runner_y]]).transpose().apply(tuple,\n",
    "                                                                                                           axis=1)\n",
    "            tuple_class_prob.columns = [f\"top{i+1}\"+str(i) for i in range(1, self._n+1)]\n",
    "            for i in range(len(tuple_class_prob)): #sorts the tuple table\n",
    "                list_to_sort=tuple_class_prob.iloc[i].tolist()\n",
    "                list_to_sort.sort(key=lambda x: -x[1])\n",
    "                tuple_class_prob.iloc[i]=list_to_sort\n",
    "            return tuple_class_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.013731,
     "end_time": "2020-01-23T11:42:07.602281",
     "exception": false,
     "start_time": "2020-01-23T11:42:07.588550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MLflow_model = STMPredProba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 1.889006,
     "end_time": "2020-01-23T11:42:09.497671",
     "exception": false,
     "start_time": "2020-01-23T11:42:07.608665",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "MLflow_model.fit(data)\n",
    "\n",
    "MLflow_model.predict(data)\n",
    "mlflow.sklearn.log_model(MLflow_model,'SupTopModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.008319,
     "end_time": "2020-01-23T11:42:09.515119",
     "exception": false,
     "start_time": "2020-01-23T11:42:09.506800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "papermill": {
   "duration": 4.096792,
   "end_time": "2020-01-23T11:42:09.929287",
   "environment_variables": {},
   "exception": null,
   "input_path": "./dummytrain.ipynb",
   "output_path": "./dummytrain_out.ipynb",
   "parameters": {
    "experimentName": "abc",
    "runID": "0f3dcdc5c5874579b60e6a802817a9cd"
   },
   "start_time": "2020-01-23T11:42:05.832495",
   "version": "1.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}